{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tulasiram58827/ocr_tflite/blob/main/colabs/ocr_tflite_inference.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6_h-40Ob7ktB"
   },
   "outputs": [],
   "source": [
    "!pip install tf-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Q9KqAypp7qDB",
    "outputId": "e7c66e27-3c6b-4d7c-e035-77e3de6c8b05"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KatIKEGv7qFa",
    "outputId": "f3cd6712-e7ec-4603-dad7-4c0a9a60ba29"
   },
   "outputs": [],
   "source": [
    "!curl -LO https://github.com/AakashKumarNain/CaptchaCracker/raw/master/captcha_images_v2.zip\n",
    "!unzip -qq captcha_images_v2.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGK7ucLq7yVc",
    "outputId": "664c1f83-a4b7-45c0-ca7e-8edc1e2d2544"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Path to the data directory\n",
    "data_dir = Path(\"./captcha_images_v2/\")\n",
    "\n",
    "# Get list of all the images\n",
    "images = sorted(list(map(str, list(data_dir.glob(\"*.png\")))))\n",
    "labels = [img.split(os.path.sep)[-1].split(\".png\")[0] for img in images]\n",
    "characters = set(char for label in labels for char in label)\n",
    "\n",
    "print(\"Number of images found: \", len(images))\n",
    "print(\"Number of labels found: \", len(labels))\n",
    "print(\"Number of unique characters: \", len(characters))\n",
    "print(\"Characters present: \", characters)\n",
    "\n",
    "# Batch size for training and validation\n",
    "batch_size = 16\n",
    "\n",
    "# Desired image dimensions\n",
    "img_width = 200\n",
    "img_height = 50\n",
    "\n",
    "# Factor by which the image is going to be downsampled\n",
    "# by the convolutional blocks. We will be using two\n",
    "# convolution blocks and each block will have\n",
    "# a pooling layer which downsample the features by a factor of 2.\n",
    "# Hence total downsampling factor would be 4.\n",
    "downsample_factor = 4\n",
    "\n",
    "# Maximum length of any captcha in the dataset\n",
    "max_length = max([len(label) for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTAMCW7QJFVL",
    "outputId": "94e04037-1ee2-4f27-ccb0-d8e222f7e47c"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/tulasiram58827/ocr_tflite/raw/main/models/ocr_dr.tflite\n",
    "!wget https://raw.githubusercontent.com/tulasiram58827/ocr_tflite/main/utilities/num_to_char.json\n",
    "!wget https://raw.githubusercontent.com/tulasiram58827/ocr_tflite/main/utilities/char_to_num.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B_n9BRlY7_LM"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('char_to_num.json', 'r') as fp:\n",
    "    char_to_num_dict = json.load(fp)\n",
    "\n",
    "with open('num_to_char.json', 'r') as fp:\n",
    "    num_to_char_dict = json.load(fp)\n",
    "\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][\n",
    "        :, :max_length\n",
    "    ]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = \"\".join([num_to_char_dict[str(val)] for val in res.numpy()])\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "NEndY4E67qG_",
    "outputId": "e0a06406-dbc5-4952-b1c8-e4eb4b9e9f52"
   },
   "outputs": [],
   "source": [
    "# Inference with TFLite\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "image_path = '/content/captcha_images_v2/226md.png'\n",
    "# 1. Read image\n",
    "img = tf.io.read_file(image_path)\n",
    "# 2. Decode and convert to grayscale\n",
    "img = tf.io.decode_png(img, channels=1)\n",
    "# 3. Convert to float32 in [0, 1] range\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "# 4. Resize to the desired size\n",
    "img = tf.image.resize(img, [img_height, img_width])\n",
    "# 5. Transpose the image because we want the time\n",
    "# dimension to correspond to the width of the image.\n",
    "img = tf.transpose(img, perm=[1, 0, 2])\n",
    "interpreter = tf.lite.Interpreter(model_path=\"ocr_dr.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.expand_dims(img, 0)\n",
    "# input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "interpreter.invoke()\n",
    "\n",
    "# The function `get_tensor()` returns a copy of the tensor data.\n",
    "# Use `tensor()` in order to get a pointer to the tensor.\n",
    "preds = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "print(pred_texts)\n",
    "\n",
    "show_image = cv2.imread(image_path)\n",
    "cv2_imshow(show_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KVUMETVB-9KV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ocr_tflite_inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
